{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd7a483",
   "metadata": {},
   "source": [
    "# Interview Day Approach\n",
    "Your Process:\n",
    "\n",
    "Clarify requirements (2 min) - \"Should I filter for minimum games played?\"\n",
    "Explore data briefly (2 min) - df.shape, df.columns, df.head()\n",
    "Code solution (10 min) - Think out loud, explain basketball context\n",
    "Test & explain (5 min) - Run code, interpret results\n",
    "\n",
    "Differentiating Factors:\n",
    "\n",
    "Basketball intuition - \"I'll filter for players with meaningful minutes\"\n",
    "Domain knowledge - \"True shooting is better than FG% because it includes free throws\"\n",
    "Data quality awareness - \"Let me check for division by zero in percentages\"\n",
    "\n",
    "You're extremely well-prepared. The combination of your comprehensive basketball datasets, statistical knowledge, and programming skills puts you ahead of most candidates. Focus on staying calm, thinking out loud, and demonstrating your basketball understanding - that's what will set you apart from generic data science candidates.\n",
    "The fact that they said \"easy\" suggests they're testing fundamentals and cultural fit rather than trying to stump you. Trust your preparation and let your basketball passion show through your technical solutions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Most Likely Question Types (Given 15-20 min + \"Easy\")\n",
    "High Probability (80%+):\n",
    "\n",
    "Basic ranking/filtering - \"Find top N players by X metric\"\n",
    "Simple aggregation - \"Which team has the highest average Y?\"\n",
    "Basketball calculation - \"Calculate shooting percentage\" or \"Find players with double-doubles\"\n",
    "\n",
    "Medium Probability (50%+):\n",
    "4. Data cleaning - Handle missing values or obvious errors\n",
    "5. Correlation/relationship - \"What's the relationship between minutes and points?\"\n",
    "Lower Probability (20%+):\n",
    "6. Advanced metrics - Calculate TS% or other efficiency measures\n",
    "7. Statistical testing - Compare groups or find outliers\n",
    "\n",
    "\n",
    "\n",
    "## Interview Best Practices\n",
    "\n",
    "### 1. **Start with Data Exploration**\n",
    "```python\n",
    "# Always begin with these\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "```\n",
    "\n",
    "### 2. **Handle Edge Cases**\n",
    "```python\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle division by zero\n",
    "df['efficiency'] = df['PTS'] / df['FGA'].replace(0, np.nan)\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "qualified_players = df[df['games'] >= 10]  # or minutes >= 500\n",
    "```\n",
    "\n",
    "### 3. **Use Clear Variable Names**\n",
    "```python\n",
    "# Good\n",
    "top_scorers = df.nlargest(5, 'points_per_game')\n",
    "\n",
    "# Not ideal\n",
    "ts = df.nlargest(5, 'ppg')\n",
    "```\n",
    "\n",
    "### 4. **Show Your Basketball Knowledge**\n",
    "```python\n",
    "# Demonstrate understanding of basketball concepts\n",
    "# True Shooting %, PER, usage rate, pace-adjusted stats\n",
    "```\n",
    "\n",
    "### 5. **Think Out Loud**\n",
    "- Explain your approach before coding\n",
    "- Mention assumptions you're making\n",
    "- Discuss potential improvements or extensions\n",
    "\n",
    "### 6. **Common Functions to Know**\n",
    "```python\n",
    "# Data manipulation\n",
    "df.groupby().agg()\n",
    "df.merge()\n",
    "df.pivot_table()\n",
    "df.query()\n",
    "df.nlargest() / df.nsmallest()\n",
    "\n",
    "# Statistical\n",
    "df.corr()\n",
    "df.describe()\n",
    "pd.cut() / pd.qcut()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Likely Question Formats\n",
    "\n",
    "1. **\"Find the top N players by [metric]\"** - Basic ranking\n",
    "2. **\"What's the relationship between X and Y?\"** - Correlation analysis  \n",
    "3. **\"Which team/player is the most/least [characteristic]?\"** - Aggregation\n",
    "4. **\"Calculate [basketball metric] for these players\"** - Domain knowledge\n",
    "5. **\"Clean this data issue\"** - Data manipulation\n",
    "6. **\"Are there any interesting patterns in this data?\"** - Exploratory analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Final Tips\n",
    "\n",
    "- **Stay calm** - 15-20 minutes is generous for most questions\n",
    "- **Ask clarifying questions** if requirements are unclear\n",
    "- **Test your code** with small examples\n",
    "- **Handle errors gracefully** (try/except if needed)\n",
    "- **Show basketball intuition** - they hired you for basketball analytics\n",
    "- **Be ready to explain** your approach and any trade-offs\n",
    "- **Practice with your existing datasets** - you have everything you need!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "Test Yourself Now:\n",
    "\n",
    "Load your player_season_master dataset\n",
    "Practice these 5 questions in under 4 minutes each:\n",
    "\n",
    "Top 10 scorers with 40+ games\n",
    "Teams ranked by average rebounds per game\n",
    "Players shooting >45% FG with >15 PPG\n",
    "Correlation between minutes and assists\n",
    "Handle any missing values in shooting percentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1d173",
   "metadata": {},
   "source": [
    "# start up the problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185700a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/5080_gpu/interview_prep/data/schema.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/5080_gpu/interview_prep/data/schema.yaml\n",
    "# schema.yaml\n",
    "# for data preprocessing and joining:\n",
    "strings: \n",
    "# player data=======\n",
    "- lastName\n",
    "- personId\n",
    "- gameId\n",
    "- gameDate\n",
    "- playerteamCity\n",
    "- playerteamName\n",
    "- opponentteamCity\n",
    "- opponentteamName\n",
    "- gameType\n",
    "- gameLabel\n",
    "- gameSubLabel\n",
    "- seriesGameNumber\n",
    "\n",
    "# team data=======\n",
    "- gameId\n",
    "- gameDate\n",
    "- teamCity\n",
    "- teamName\n",
    "- teamId\n",
    "- opponentTeamCity\n",
    "- opponentTeamName\n",
    "- opponentTeamId\n",
    "- coachId\n",
    "\n",
    "numerics: \n",
    "# player data=======\n",
    "- lastName\n",
    "- personId\n",
    "- gameId\n",
    "- gameDate\n",
    "- playerteamCity\n",
    "- playerteamName\n",
    "- opponentteamCity\n",
    "- opponentteamName\n",
    "- gameType\n",
    "- gameLabel\n",
    "- gameSubLabel\n",
    "- seriesGameNumber\n",
    "- win\n",
    "- home\n",
    "- numMinutes\n",
    "- points\n",
    "- assists\n",
    "- blocks\n",
    "- steals\n",
    "- fieldGoalsAttempted\n",
    "- fieldGoalsMade\n",
    "- fieldGoalsPercentage\n",
    "- threePointersAttempted\n",
    "- threePointersMade\n",
    "- threePointersPercentage\n",
    "- freeThrowsAttempted\n",
    "- freeThrowsMade\n",
    "- freeThrowsPercentage\n",
    "- reboundsDefensive\n",
    "- reboundsOffensive\n",
    "- reboundsTotal\n",
    "- foulsPersonal\n",
    "- turnovers\n",
    "- plusMinusPoints\n",
    "- season\n",
    "- player_name\n",
    "- minutes_total\n",
    "\n",
    "# team data=======\n",
    "- home\n",
    "- win\n",
    "- teamScore\n",
    "- opponentScore\n",
    "- assists\n",
    "- blocks\n",
    "- steals\n",
    "- fieldGoalsAttempted\n",
    "- fieldGoalsMade\n",
    "- fieldGoalsPercentage\n",
    "- threePointersAttempted\n",
    "- threePointersMade\n",
    "- threePointersPercentage\n",
    "- freeThrowsAttempted\n",
    "- freeThrowsMade\n",
    "- freeThrowsPercentage\n",
    "- reboundsDefensive\n",
    "- reboundsOffensive\n",
    "- reboundsTotal\n",
    "- foulsPersonal\n",
    "- turnovers\n",
    "- plusMinusPoints\n",
    "- numMinutes\n",
    "- q1Points\n",
    "- q2Points\n",
    "- q3Points\n",
    "- q4Points\n",
    "- benchPoints\n",
    "- biggestLead\n",
    "- biggestScoringRun\n",
    "- leadChanges\n",
    "- pointsFastBreak\n",
    "- pointsFromTurnovers\n",
    "- pointsInThePaint\n",
    "- pointsSecondChance\n",
    "- timesTied\n",
    "- timeoutsRemaining\n",
    "- seasonWins\n",
    "- seasonLosses\n",
    "- season\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# NBA Player Season Data Schema\n",
    "\n",
    "\n",
    "# Target variable for analysis\n",
    "y_variable: \n",
    "\n",
    "# Ordinal variables (ordered categories)\n",
    "ordinal: \n",
    "\n",
    "\n",
    "# Nominal variables (unordered categories) \n",
    "nominal: \n",
    "\n",
    "\n",
    "# Numerical variables (continuous/discrete numbers)\n",
    "numerical: \n",
    "\n",
    "\n",
    "# ID columns (identifiers, not used in modeling)\n",
    "id_cols: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad48859",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for ColumnSchema\ny_variable\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nordinal\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nnominal\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nnumerical\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nid_cols\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 143\u001b[0m\n\u001b[1;32m    140\u001b[0m team_df_csv_path \u001b[38;5;241m=\u001b[39m Path(base \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteam_statistics_used_Regular Season_from_2009.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    141\u001b[0m schema_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebooks/5080_gpu/interview_prep/data/schema.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# FIXED: Convert to Path object\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mload_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mschema_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m player_data \u001b[38;5;241m=\u001b[39m load_data(player_df_csv_path, schema, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    146\u001b[0m team_data \u001b[38;5;241m=\u001b[39m load_data(team_df_csv_path, schema, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[2], line 109\u001b[0m, in \u001b[0;36mload_schema\u001b[0;34m(yaml_path, debug)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcfg_dict=============\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mColumnSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/.venv/lib/python3.10/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for ColumnSchema\ny_variable\n  Input should be a valid string [type=string_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/string_type\nordinal\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nnominal\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nnumerical\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type\nid_cols\n  Input should be a valid list [type=list_type, input_value=None, input_type=NoneType]\n    For further information visit https://errors.pydantic.dev/2.11/v/list_type"
     ]
    }
   ],
   "source": [
    "#%%writefile notebooks/5080_gpu/interview_prep/main.py\n",
    "\"\"\"\n",
    "NBA Analysis Pipeline - Optimized for Live Coding Assessments\n",
    "============================================================\n",
    "\n",
    "\n",
    "# Detailed Questions for set up \n",
    "\n",
    "Start by:\n",
    "working through the datasets to create VORP, EWA, PER, PIE, and PER in basic steps so that we can easily do this ourselves in easy code. Then let's answer the questions below in order while creating easy to use and write functions that can do these. \n",
    "\n",
    "Questions:\n",
    "“Given a CSV dataset, how would you explore and summarize it?”\n",
    "\n",
    "“Given a DataFrame, how would you handle missing values?”\n",
    "\n",
    "“How would you detect and address outliers in a dataset?”\n",
    "\n",
    "“Perform univariate, bivariate, and multivariate analysis on given columns.”\n",
    "\n",
    "“Given a dataset, how would you normalize or standardize its features?”\n",
    "\n",
    "“Write a function to compute summary statistics (mean, median, std, etc.) of a column.”\n",
    "\n",
    "“Given a dataset, how would you identify the type of each variable and choose feature encoding?”\n",
    "\n",
    "“Given a dataset and a target variable, how would you check for relationships or correlations?”\n",
    "\n",
    "“Write code to detect missingness patterns and decide how to impute.”\n",
    "\n",
    "“Describe the full data-analysis pipeline: from loading to insight delivery—then code accordingly.”\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interview questions:\n",
    "1) \"Who are the top 5 players by points per game this season?\"\n",
    "2) \"Find all players who average more than 25 PPG and 10 RPG\"\n",
    "3) \"What's the correlation between minutes played and points scored?\"\n",
    "\n",
    "4) \"Calculate shooting efficiency - players with best True Shooting %\"\n",
    "5) \"Find the most 'complete' players - top 10 in points + assists + rebounds\"\n",
    "6) \"Which team has the most balanced scoring attack?\"\n",
    "\n",
    "7) \"Clean this dataset - handle missing values in FG%\"\n",
    "8) \"Group players by minutes played tiers and show average stats\"\n",
    "\n",
    "9) \"Is there a significant difference in scoring between guards and forwards?\"\n",
    "10) \"Find players who are outliers in efficiency\"\n",
    "\n",
    "11) \"Who improved the most from last season to this season?\"\n",
    "12) \"Calculate Player Impact Estimate (PIE) for top 10 players\"\n",
    "\n",
    "\n",
    "--\n",
    "13) Who are the top 3 scorers **per team** by **points per-36** (filter to minutes ≥ 15)?\n",
    "\n",
    "14) Build a simple **composite impact score** per player using standardized per-36 stats:\n",
    "   `impact = z(points/36) + 0.7*z(assists/36) + 0.7*z(rebounds/36)`. Who are the top 10?\n",
    "\n",
    "15) Do players **outperform their expected points** for their minutes/assists/rebounds?\n",
    "   Fit a quick linear model `points ~ minutes + assists + rebounds` and list top 10 **positive residuals**.\n",
    "\n",
    "16) Which team is **most balanced vs. star-heavy** by scoring?\n",
    "   Compute **coefficient of variation** (std/mean) of `points` per team and rank.\n",
    "\n",
    "17) Bucket players into **minutes tiers**: `[10–19, 20–29, 30–40]`.\n",
    "   What are the mean/median of `points/assists/rebounds` per tier?\n",
    "\n",
    "18) “Three-above-median” players: per team, who is **above the team median** in **points, assists, and rebounds** simultaneously?\n",
    "\n",
    "19) Write a reusable helper `top_k(df, by, k, group=None)` and use it to return the **top 2 rebounders per team**.\n",
    "\n",
    "20) What’s the **team effect** on scoring after controlling for other stats?\n",
    "   One-hot encode `team`, fit a Ridge `points ~ minutes + assists + rebounds + team_*`, and show team coefficients.\n",
    "\n",
    "21) Give a quick **bootstrap 95% CI** for **mean points per team** (1,000 resamples). Which teams have clearly higher means?\n",
    "\n",
    "22) Detect potential **duplicate identity issues**: do we have any duplicate `(player_id, name)` rows? If so, keep the one with the **max minutes**.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ColumnSchema(BaseModel):\n",
    "    y_variable: str\n",
    "    ordinal: List[str]\n",
    "    nominal: List[str]\n",
    "    numerical: List[str]\n",
    "    id_cols: List[str]\n",
    "    strings: List[str]\n",
    "    numerics: List[str]\n",
    "    \n",
    "    \n",
    "def load_schema(yaml_path, debug=False):\n",
    "    cfg = OmegaConf.load(yaml_path)\n",
    "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "    if debug:\n",
    "        print(f\"cfg_dict============={cfg_dict}\")\n",
    "    return ColumnSchema(**cfg_dict)\n",
    "\n",
    "\n",
    "def load_data(csv_path: str, schema: ColumnSchema,  sample_size: int = 100, sample: bool = False, debug: bool = False):\n",
    "    dtype_data = pd.read_csv(csv_path, nrows=sample_size)\n",
    "    if debug:\n",
    "        print(f\"data types from the dataset======={dtype_data.dtypes}\")\n",
    "    \n",
    "    dtype_map = {}\n",
    "    \n",
    "    for cols in schema.strings:\n",
    "        if cols in dtype_data.columns:\n",
    "            dtype_map = \"string\"\n",
    "\n",
    "    if sample:\n",
    "        data = pd.read_csv(csv_path, nrows=sample_size)\n",
    "    else:\n",
    "        data = pd.read_csv(csv_path, dtype=dtype_map)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"updated data types from the dataset======={dtype_data.dtypes}\")\n",
    "        \n",
    "    for col in schema.numerics:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base = Path(\"notebooks/5080_gpu/interview_prep/data/heat_base_data\")\n",
    "    player_df_csv_path = Path(base / \"player_statistics_used_Regular Season_from_2009.csv\")\n",
    "    team_df_csv_path = Path(base / \"team_statistics_used_Regular Season_from_2009.csv\")\n",
    "    schema_path = Path(\"notebooks/5080_gpu/interview_prep/data/schema.yaml\")  # FIXED: Convert to Path object\n",
    "    \n",
    "    schema = load_schema(schema_path)\n",
    "    \n",
    "    player_data = load_data(player_df_csv_path, schema, debug=True)\n",
    "    team_data = load_data(team_df_csv_path, schema, debug=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa26054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
