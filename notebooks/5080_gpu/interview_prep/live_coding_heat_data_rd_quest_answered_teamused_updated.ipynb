{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd7a483",
   "metadata": {},
   "source": [
    "# Interview Day Approach\n",
    "Your Process:\n",
    "\n",
    "Clarify requirements (2 min) - \"Should I filter for minimum games played?\"\n",
    "Explore data briefly (2 min) - df.shape, df.columns, df.head()\n",
    "Code solution (10 min) - Think out loud, explain basketball context\n",
    "Test & explain (5 min) - Run code, interpret results\n",
    "\n",
    "Differentiating Factors:\n",
    "\n",
    "Basketball intuition - \"I'll filter for players with meaningful minutes\"\n",
    "Domain knowledge - \"True shooting is better than FG% because it includes free throws\"\n",
    "Data quality awareness - \"Let me check for division by zero in percentages\"\n",
    "\n",
    "You're extremely well-prepared. The combination of your comprehensive basketball datasets, statistical knowledge, and programming skills puts you ahead of most candidates. Focus on staying calm, thinking out loud, and demonstrating your basketball understanding - that's what will set you apart from generic data science candidates.\n",
    "The fact that they said \"easy\" suggests they're testing fundamentals and cultural fit rather than trying to stump you. Trust your preparation and let your basketball passion show through your technical solutions.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Most Likely Question Types (Given 15-20 min + \"Easy\")\n",
    "High Probability (80%+):\n",
    "\n",
    "Basic ranking/filtering - \"Find top N players by X metric\"\n",
    "Simple aggregation - \"Which team has the highest average Y?\"\n",
    "Basketball calculation - \"Calculate shooting percentage\" or \"Find players with double-doubles\"\n",
    "\n",
    "Medium Probability (50%+):\n",
    "4. Data cleaning - Handle missing values or obvious errors\n",
    "5. Correlation/relationship - \"What's the relationship between minutes and points?\"\n",
    "Lower Probability (20%+):\n",
    "6. Advanced metrics - Calculate TS% or other efficiency measures\n",
    "7. Statistical testing - Compare groups or find outliers\n",
    "\n",
    "\n",
    "\n",
    "## Interview Best Practices\n",
    "\n",
    "### 1. **Start with Data Exploration**\n",
    "```python\n",
    "# Always begin with these\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "```\n",
    "\n",
    "### 2. **Handle Edge Cases**\n",
    "```python\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle division by zero\n",
    "df['efficiency'] = df['PTS'] / df['FGA'].replace(0, np.nan)\n",
    "\n",
    "# Filter for meaningful sample sizes\n",
    "qualified_players = df[df['games'] >= 10]  # or minutes >= 500\n",
    "```\n",
    "\n",
    "### 3. **Use Clear Variable Names**\n",
    "```python\n",
    "# Good\n",
    "top_scorers = df.nlargest(5, 'points_per_game')\n",
    "\n",
    "# Not ideal\n",
    "ts = df.nlargest(5, 'ppg')\n",
    "```\n",
    "\n",
    "### 4. **Show Your Basketball Knowledge**\n",
    "```python\n",
    "# Demonstrate understanding of basketball concepts\n",
    "# True Shooting %, PER, usage rate, pace-adjusted stats\n",
    "```\n",
    "\n",
    "### 5. **Think Out Loud**\n",
    "- Explain your approach before coding\n",
    "- Mention assumptions you're making\n",
    "- Discuss potential improvements or extensions\n",
    "\n",
    "### 6. **Common Functions to Know**\n",
    "```python\n",
    "# Data manipulation\n",
    "df.groupby().agg()\n",
    "df.merge()\n",
    "df.pivot_table()\n",
    "df.query()\n",
    "df.nlargest() / df.nsmallest()\n",
    "\n",
    "# Statistical\n",
    "df.corr()\n",
    "df.describe()\n",
    "pd.cut() / pd.qcut()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Likely Question Formats\n",
    "\n",
    "1. **\"Find the top N players by [metric]\"** - Basic ranking\n",
    "2. **\"What's the relationship between X and Y?\"** - Correlation analysis  \n",
    "3. **\"Which team/player is the most/least [characteristic]?\"** - Aggregation\n",
    "4. **\"Calculate [basketball metric] for these players\"** - Domain knowledge\n",
    "5. **\"Clean this data issue\"** - Data manipulation\n",
    "6. **\"Are there any interesting patterns in this data?\"** - Exploratory analysis\n",
    "\n",
    "---\n",
    "\n",
    "## Final Tips\n",
    "\n",
    "- **Stay calm** - 15-20 minutes is generous for most questions\n",
    "- **Ask clarifying questions** if requirements are unclear\n",
    "- **Test your code** with small examples\n",
    "- **Handle errors gracefully** (try/except if needed)\n",
    "- **Show basketball intuition** - they hired you for basketball analytics\n",
    "- **Be ready to explain** your approach and any trade-offs\n",
    "- **Practice with your existing datasets** - you have everything you need!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------------------\n",
    "\n",
    "\n",
    "Test Yourself Now:\n",
    "\n",
    "Load your player_season_master dataset\n",
    "Practice these 5 questions in under 4 minutes each:\n",
    "\n",
    "Top 10 scorers with 40+ games\n",
    "Teams ranked by average rebounds per game\n",
    "Players shooting >45% FG with >15 PPG\n",
    "Correlation between minutes and assists\n",
    "Handle any missing values in shooting percentages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3376e",
   "metadata": {},
   "source": [
    "# 🏀 NBA Data Science Live Coding Cheatsheet\n",
    "\n",
    "## **Live Coding EDA Cheatsheet**\n",
    "\n",
    "\n",
    "--- Data Exploration & Basic EDA ---\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(df.head(3))\n",
    "print(df.info()) # Full columns and dtypes\n",
    "print(df.describe(include='all')) # Summary stats\n",
    "\n",
    "--- Nulls and Dtypes ---\n",
    "print(df.isnull().sum()) # Null count per column\n",
    "print(df.dtypes) # Column data types\n",
    "\n",
    "--- Quick Summary for All Columns ---\n",
    "print(df.nunique()) # Unique values per column\n",
    "print(df.sample(3)) # Random sample\n",
    "\n",
    "--- Filtering/Slicing ---\n",
    "df = df[df[\"minutes\"] > 500] # Filter for minimum minutes\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "--- Value Counts (Categorical) ---\n",
    "print(df[\"team\"].value_counts())\n",
    "\n",
    "\n",
    "## **Pandas Joins/Merges Cheatsheet**\n",
    "\n",
    "**Common DataFrame Join Syntax**\n",
    "\n",
    "\n",
    "Left join (SQL-like)\n",
    "df = df1.merge(df2, how=\"left\", on=\"key_col\")\n",
    "\n",
    "Inner join (intersection)\n",
    "df = df1.merge(df2, how=\"inner\", on=\"key_col\")\n",
    "\n",
    "Outer join (all rows)\n",
    "df = df1.merge(df2, how=\"outer\", on=\"key_col\")\n",
    "\n",
    "Right join\n",
    "df = df1.merge(df2, how=\"right\", on=\"key_col\")\n",
    "\n",
    "Multi-key merge\n",
    "df = df1.merge(df2, how=\"left\", on=[\"season\", \"player_id\"])\n",
    "\n",
    "Validation (optional, prevents duplicate matches)\n",
    "df = df1.merge(df2, how=\"left\", on=\"key_col\", validate=\"one_to_one\")\n",
    "\n",
    "Anti-join: Rows in df1, not in df2\n",
    "anti = df1[~df1[\"key_col\"].isin(df2[\"key_col\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1d173",
   "metadata": {},
   "source": [
    "# start up the problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185700a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting notebooks/5080_gpu/interview_prep/data/schema.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/5080_gpu/interview_prep/data/schema.yaml\n",
    "# schema.yaml\n",
    "# NBA Player Season Data Schema\n",
    "\n",
    "# Target variable for analysis\n",
    "y_variable: \"PTS\"\n",
    "\n",
    "# Ordinal variables (ordered categories)\n",
    "ordinal: \n",
    "  - \"minutes_tier\"\n",
    "  - \"season\"\n",
    "\n",
    "# Nominal variables (unordered categories) \n",
    "nominal: \n",
    "  - \"playerteamCity\"\n",
    "  - \"playerteamName\"\n",
    "  - \"opponentteamCity\" \n",
    "  - \"opponentteamName\"\n",
    "  - \"gameType\"\n",
    "  - \"firstName\"\n",
    "  - \"lastName\"\n",
    "  - \"name\"\n",
    "  - \"team\"\n",
    "\n",
    "# Numerical variables (continuous/discrete numbers)\n",
    "numerical: \n",
    "  # Basic box score stats\n",
    "  - \"minutes\"\n",
    "  - \"PTS\"\n",
    "  - \"AST\" \n",
    "  - \"TRB\"\n",
    "  - \"OREB\"\n",
    "  - \"DREB\"\n",
    "  - \"STL\"\n",
    "  - \"BLK\"\n",
    "  - \"TOV\"\n",
    "  - \"FGA\"\n",
    "  - \"FGM\"\n",
    "  - \"FTA\"\n",
    "  - \"FTM\"\n",
    "  - \"3PA\"\n",
    "  - \"3PM\"\n",
    "  - \"PF\"\n",
    "  - \"games\"\n",
    "  \n",
    "  # Calculated percentages\n",
    "  - \"FG_pct\"\n",
    "  - \"FT_pct\"\n",
    "  - \"TS_pct\"\n",
    "  - \"TSA\"\n",
    "  - \"threePointersPercentage\"\n",
    "  - \"fieldGoalsPercentage\"\n",
    "  - \"freeThrowsPercentage\"\n",
    "  \n",
    "  # Per-game stats\n",
    "  - \"PPG\"\n",
    "  - \"APG\"\n",
    "  - \"RPG\"\n",
    "  - \"MPG\"\n",
    "  \n",
    "  # Per-36 stats\n",
    "  - \"PTS_per36\"\n",
    "  - \"AST_per36\"\n",
    "  - \"TRB_per36\"\n",
    "  - \"STL_per36\"\n",
    "  - \"BLK_per36\"\n",
    "  - \"TOV_per36\"\n",
    "  \n",
    "  # Advanced metrics\n",
    "  - \"season_PIE\"\n",
    "  - \"season_BMP\" \n",
    "  - \"season_VORP\"\n",
    "  - \"season_EWA\"\n",
    "  - \"season_PER\"\n",
    "  - \"efficiency\"\n",
    "  - \"impact_score\"\n",
    "  \n",
    "  # Game context\n",
    "  - \"plusMinusPoints\"\n",
    "  - \"home\"\n",
    "  - \"win\"\n",
    "  - \"seriesGameNumber\"\n",
    "\n",
    "# ID columns (identifiers, not used in modeling)\n",
    "id_cols: \n",
    "  - \"personId\"\n",
    "  - \"player_id\"\n",
    "  - \"gameId\"\n",
    "  - \"game_id\"\n",
    "  - \"teamId\"\n",
    "  - \"opponentTeamId\"\n",
    "  - \"gameDate\"\n",
    "  - \"gameLabel\"\n",
    "  - \"gameSubLabel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad48859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing notebooks/5080_gpu/interview_prep/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile notebooks/5080_gpu/interview_prep/main.py\n",
    "\"\"\"\n",
    "NBA Analysis Pipeline - Optimized for Live Coding Assessments\n",
    "============================================================\n",
    "\n",
    "\n",
    "# Detailed Questions for set up \n",
    "\n",
    "Start by:\n",
    "working through the datasets to create VORP, EWA, PER, PIE, and PER in basic steps so that we can easily do this ourselves in easy code. Then let's answer the questions below in order while creating easy to use and write functions that can do these. \n",
    "\n",
    "Questions:\n",
    "“Given a CSV dataset, how would you explore and summarize it?”\n",
    "\n",
    "“Given a DataFrame, how would you handle missing values?”\n",
    "\n",
    "“How would you detect and address outliers in a dataset?”\n",
    "\n",
    "“Perform univariate, bivariate, and multivariate analysis on given columns.”\n",
    "\n",
    "“Given a dataset, how would you normalize or standardize its features?”\n",
    "\n",
    "“Write a function to compute summary statistics (mean, median, std, etc.) of a column.”\n",
    "\n",
    "“Given a dataset, how would you identify the type of each variable and choose feature encoding?”\n",
    "\n",
    "“Given a dataset and a target variable, how would you check for relationships or correlations?”\n",
    "\n",
    "“Write code to detect missingness patterns and decide how to impute.”\n",
    "\n",
    "“Describe the full data-analysis pipeline: from loading to insight delivery—then code accordingly.”\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "interview questions:\n",
    "1) \"Who are the top 5 players by points per game this season?\"\n",
    "2) \"Find all players who average more than 25 PPG and 10 RPG\"\n",
    "3) \"What's the correlation between minutes played and points scored?\"\n",
    "\n",
    "4) \"Calculate shooting efficiency - players with best True Shooting %\"\n",
    "5) \"Find the most 'complete' players - top 10 in points + assists + rebounds\"\n",
    "6) \"Which team has the most balanced scoring attack?\"\n",
    "\n",
    "7) \"Clean this dataset - handle missing values in FG%\"\n",
    "8) \"Group players by minutes played tiers and show average stats\"\n",
    "\n",
    "9) \"Is there a significant difference in scoring between guards and forwards?\"\n",
    "10) \"Find players who are outliers in efficiency\"\n",
    "\n",
    "11) \"Who improved the most from last season to this season?\"\n",
    "12) \"Calculate Player Impact Estimate (PIE) for top 10 players\"\n",
    "\n",
    "\n",
    "--\n",
    "13) Who are the top 3 scorers **per team** by **points per-36** (filter to minutes ≥ 15)?\n",
    "\n",
    "14) Build a simple **composite impact score** per player using standardized per-36 stats:\n",
    "   `impact = z(points/36) + 0.7*z(assists/36) + 0.7*z(rebounds/36)`. Who are the top 10?\n",
    "\n",
    "15) Do players **outperform their expected points** for their minutes/assists/rebounds?\n",
    "   Fit a quick linear model `points ~ minutes + assists + rebounds` and list top 10 **positive residuals**.\n",
    "\n",
    "16) Which team is **most balanced vs. star-heavy** by scoring?\n",
    "   Compute **coefficient of variation** (std/mean) of `points` per team and rank.\n",
    "\n",
    "17) Bucket players into **minutes tiers**: `[10–19, 20–29, 30–40]`.\n",
    "   What are the mean/median of `points/assists/rebounds` per tier?\n",
    "\n",
    "18) “Three-above-median” players: per team, who is **above the team median** in **points, assists, and rebounds** simultaneously?\n",
    "\n",
    "19) Write a reusable helper `top_k(df, by, k, group=None)` and use it to return the **top 2 rebounders per team**.\n",
    "\n",
    "20) What’s the **team effect** on scoring after controlling for other stats?\n",
    "   One-hot encode `team`, fit a Ridge `points ~ minutes + assists + rebounds + team_*`, and show team coefficients.\n",
    "\n",
    "21) Give a quick **bootstrap 95% CI** for **mean points per team** (1,000 resamples). Which teams have clearly higher means?\n",
    "\n",
    "22) Detect potential **duplicate identity issues**: do we have any duplicate `(player_id, name)` rows? If so, keep the one with the **max minutes**.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler  # Added for Ridge regression\n",
    "from pydantic import BaseModel\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# ============================================================================\n",
    "# HELPERS\n",
    "# ============================================================================\n",
    "\n",
    "def add_per36(df: pd.DataFrame, stat_cols: list[str], minutes_col: str = \"minutes\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute per-36 values for the given season-level totals.\n",
    "    - Does NOT fill NaNs; if minutes == 0 -> NaN (surfaces data issues instead of masking them).\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    if minutes_col not in d.columns:\n",
    "        raise KeyError(f\"'{minutes_col}' not found on DataFrame needed for per-36.\")\n",
    "    mins = d[minutes_col].astype(float)\n",
    "    missing_cols = []\n",
    "    for s in stat_cols:\n",
    "        if s not in d.columns:\n",
    "            missing_cols.append(s)\n",
    "            continue  # don't fabricate; skip silently\n",
    "        per36_col = f\"{s}_per36\"\n",
    "        d[per36_col] = np.where(mins > 0, (d[s].astype(float) * 36.0) / mins, np.nan)\n",
    "    \n",
    "    # Explicit warning for missing columns\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Skipped missing stat columns for per-36: {missing_cols}\")\n",
    "    return d\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add z-scored versions of columns as 'z_<col>'.\n",
    "    - No imputation; if std == 0 or col is all-NaN -> resulting z_ col is NaN.\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in d.columns:\n",
    "            continue\n",
    "        col = d[c].astype(float)\n",
    "        mu = col.mean(skipna=True)\n",
    "        sigma = col.std(ddof=0, skipna=True)\n",
    "        zc = (col - mu) / sigma if sigma and not np.isnan(sigma) and sigma != 0 else np.nan\n",
    "        d[f\"z_{c}\"] = zc\n",
    "    return d\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED HELPER FUNCTIONS - Eliminates code duplication\n",
    "# ============================================================================\n",
    "\n",
    "def assign_minutes_tier(mpg):\n",
    "    \"\"\"\n",
    "    UNIFIED FUNCTION: Single source of truth for minutes tier assignment\n",
    "    Used by both question_8_minutes_tiers and question_17_minutes_tier_analysis\n",
    "    \"\"\"\n",
    "    if pd.isna(mpg):\n",
    "        return \"Other\"\n",
    "    elif 10 <= mpg < 20:\n",
    "        return \"10-19 MPG\"\n",
    "    elif 20 <= mpg < 30:\n",
    "        return \"20-29 MPG\" \n",
    "    elif 30 <= mpg <= 40:\n",
    "        return \"30-40 MPG\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "def calculate_team_scoring_balance(df: pd.DataFrame, group_cols: list = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    UNIFIED FUNCTION: Single source of truth for team scoring balance calculation\n",
    "    Used by both question_6_team_balance and question_16_team_scoring_balance\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with team and scoring data\n",
    "        group_cols: Columns to group by (default: ['team', 'season'])\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with team balance metrics\n",
    "    \"\"\"\n",
    "    if group_cols is None:\n",
    "        group_cols = ['team', 'season']\n",
    "    \n",
    "    # Ensure team column exists\n",
    "    df = add_team_column(df.copy())\n",
    "    \n",
    "    # Calculate team balance metrics\n",
    "    team_balance = (df.groupby(group_cols)['PTS']\n",
    "                   .agg(['mean', 'std', 'count'])\n",
    "                   .reset_index())\n",
    "    \n",
    "    # Calculate coefficient of variation (CV = std/mean)\n",
    "    team_balance['cv'] = (team_balance['std'] / team_balance['mean'].replace(0, np.nan))\n",
    "    \n",
    "    # Classify balance type based on median CV\n",
    "    median_cv = team_balance['cv'].median()\n",
    "    team_balance['balance_type'] = np.where(\n",
    "        team_balance['cv'] < median_cv, \n",
    "        'Balanced', \n",
    "        'Star-Heavy'\n",
    "    )\n",
    "    \n",
    "    return team_balance.sort_values('cv')\n",
    "\n",
    "def safe_mpg_calculation(df: pd.DataFrame, minutes_col: str = 'minutes', games_col: str = 'games') -> pd.Series:\n",
    "    \"\"\"\n",
    "    UNIFIED FUNCTION: Safe MPG calculation that handles edge cases\n",
    "    \n",
    "    Fixes the issue where games=0 creates inf values\n",
    "    Used by questions that need MPG calculations\n",
    "    \"\"\"\n",
    "    # Replace 0 games with NaN to avoid division by zero -> inf\n",
    "    safe_games = df[games_col].replace(0, np.nan)\n",
    "    mpg = df[minutes_col] / safe_games\n",
    "    return mpg\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CORE DATA LOADING - SIMPLIFIED\n",
    "# ============================================================================\n",
    "class ColumnSchema(BaseModel):\n",
    "    y_variable: str\n",
    "    ordinal: List[str]\n",
    "    nominal: List[str]\n",
    "    numerical: List[str]\n",
    "    id_cols: List[str]\n",
    "\n",
    "def load_schema(yaml_path: str) -> ColumnSchema:\n",
    "    \"\"\"Load schema from YAML file\"\"\"\n",
    "    cfg = OmegaConf.load(yaml_path)\n",
    "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "    return ColumnSchema(**cfg_dict)\n",
    "\n",
    "\n",
    "\n",
    "def load_data(csv_path: str, schema: ColumnSchema, sample: bool = False, sample_size: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Streamlined data loading using schema for column types\n",
    "    No complex branching - direct pandas operations\n",
    "    \"\"\"\n",
    "    # Build dtype mapping from schema\n",
    "    dtype_map = {}\n",
    "    \n",
    "    # ID columns as strings for joining\n",
    "    for col in schema.id_cols:\n",
    "        dtype_map[col] = 'string'\n",
    "    \n",
    "    # Nominal columns as categories\n",
    "    for col in schema.nominal:\n",
    "        dtype_map[col] = 'string'\n",
    "    \n",
    "    # Load data\n",
    "    if sample:\n",
    "        data = pd.read_csv(csv_path, dtype=dtype_map, nrows=sample_size)\n",
    "    else:\n",
    "        data = pd.read_csv(csv_path, dtype=dtype_map)\n",
    "    \n",
    "    # Convert numerical columns - let pandas handle the rest\n",
    "    for col in schema.numerical:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def normalize_player_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Streamlined player data normalization\n",
    "    Direct column operations without fallbacks\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    \n",
    "    # Standard column mapping - no conditional logic\n",
    "    column_mapping = {\n",
    "        'personId': 'player_id', 'gameId': 'game_id', 'numMinutes': 'minutes',\n",
    "        'points': 'PTS', 'assists': 'AST', 'reboundsTotal': 'TRB',\n",
    "        'reboundsOffensive': 'OREB', 'reboundsDefensive': 'DREB',\n",
    "        'steals': 'STL', 'blocks': 'BLK', 'turnovers': 'TOV',\n",
    "        'fieldGoalsAttempted': 'FGA', 'fieldGoalsMade': 'FGM',\n",
    "        'freeThrowsAttempted': 'FTA', 'freeThrowsMade': 'FTM',\n",
    "        'threePointersAttempted': '3PA', 'threePointersMade': '3PM',\n",
    "        'foulsPersonal': 'PF'\n",
    "    }\n",
    "    \n",
    "    d = d.rename(columns=column_mapping)\n",
    "    \n",
    "    # Create name field directly\n",
    "    d['name'] = (d['firstName'].astype('string') + ' ' + d['lastName'].astype('string')).str.strip()\n",
    "    \n",
    "    # Convert numeric stats - no error handling, let NaNs surface\n",
    "    numeric_stats = ['minutes', 'PTS', 'AST', 'TRB', 'OREB', 'DREB', \n",
    "                    'STL', 'BLK', 'TOV', 'FGA', 'FGM', 'FTA', 'FTM', '3PA', '3PM', 'PF']\n",
    "    \n",
    "    for col in numeric_stats:\n",
    "        if col in d.columns:\n",
    "            d[col] = pd.to_numeric(d[col], errors='coerce')  # Keep NaNs to surface data issues\n",
    "    \n",
    "    return d\n",
    "\n",
    "def build_season_totals(player_games: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Season aggregation with proper NaN handling\n",
    "    \n",
    "    MAIN FIX: Handles KeyError: nan by checking for valid minutes before using idxmax()\n",
    "    \"\"\"\n",
    "    if player_games.empty:\n",
    "        raise ValueError(\"Player games DataFrame cannot be empty\")\n",
    "    \n",
    "    print(f\"Building season totals from {len(player_games)} game records\")\n",
    "    \n",
    "    # FIXED: Team assignment function that handles NaN minutes\n",
    "    def get_team_assignment(group):\n",
    "        \"\"\"Get team assignment, handling NaN minutes properly\"\"\"\n",
    "        # Filter out NaN minutes before finding max\n",
    "        valid_minutes = group[group['minutes'].notna()]\n",
    "        \n",
    "        if valid_minutes.empty:\n",
    "            # If no valid minutes, use first available record\n",
    "            print(f\"Warning: No valid minutes for {group.iloc[0]['name']} in {group.iloc[0]['season']}\")\n",
    "            return group.iloc[0][['playerteamCity', 'playerteamName']]\n",
    "        else:\n",
    "            # Use the game with maximum minutes\n",
    "            max_idx = valid_minutes['minutes'].idxmax()\n",
    "            return group.loc[max_idx, ['playerteamCity', 'playerteamName']]\n",
    "    \n",
    "    # FIXED: Apply the safe team assignment function\n",
    "    try:\n",
    "        team_assignment = (\n",
    "            player_games.groupby(['player_id', 'name', 'season'])\n",
    "            .apply(get_team_assignment)\n",
    "            .reset_index()\n",
    "        )\n",
    "        print(f\"Team assignments created: {len(team_assignment)} unique player-seasons\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in team assignment: {e}\")\n",
    "        # Debug info\n",
    "        print(\"Sample of problematic data:\")\n",
    "        sample_group = player_games.groupby(['player_id', 'name', 'season']).first().head()\n",
    "        print(sample_group[['minutes', 'playerteamCity', 'playerteamName']])\n",
    "        raise\n",
    "    \n",
    "    # Aggregate stats with validation\n",
    "    agg_cols = {\n",
    "        'minutes': 'sum', 'PTS': 'sum', 'AST': 'sum', 'TRB': 'sum',\n",
    "        'OREB': 'sum', 'DREB': 'sum', 'STL': 'sum', 'BLK': 'sum',\n",
    "        'PF': 'sum', 'TOV': 'sum', 'FGA': 'sum', 'FGM': 'sum',\n",
    "        'FTA': 'sum', 'FTM': 'sum', '3PA': 'sum', '3PM': 'sum',\n",
    "        'game_id': 'nunique'\n",
    "    }\n",
    "    \n",
    "    # Only aggregate columns that exist\n",
    "    available_agg_cols = {k: v for k, v in agg_cols.items() if k in player_games.columns}\n",
    "    missing_agg_cols = [k for k in agg_cols.keys() if k not in player_games.columns]\n",
    "    \n",
    "    if missing_agg_cols:\n",
    "        print(f\"Warning: Missing aggregation columns: {missing_agg_cols}\")\n",
    "    \n",
    "    season_stats = (\n",
    "        player_games.groupby(['player_id', 'name', 'season'])\n",
    "        .agg(available_agg_cols)\n",
    "        .rename(columns={'game_id': 'games'})\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"Season stats aggregated: {len(season_stats)} player-seasons\")\n",
    "    \n",
    "    # Merge team info with validation\n",
    "    result = season_stats.merge(\n",
    "        team_assignment, \n",
    "        on=['player_id', 'name', 'season'], \n",
    "        how='left',\n",
    "        validate='one_to_one'\n",
    "    )\n",
    "    \n",
    "    # Calculate shooting percentages with proper zero handling\n",
    "    if 'FGM' in result.columns and 'FGA' in result.columns:\n",
    "        result['FG_pct'] = result['FGM'] / result['FGA'].replace(0, np.nan)\n",
    "    \n",
    "    if 'FTM' in result.columns and 'FTA' in result.columns:\n",
    "        result['FT_pct'] = result['FTM'] / result['FTA'].replace(0, np.nan)\n",
    "    \n",
    "    # Calculate True Shooting with validation\n",
    "    if all(col in result.columns for col in ['PTS', 'FGA', 'FTA']):\n",
    "        result['TSA'] = result['FGA'] + 0.44 * result['FTA']\n",
    "        result['TS_pct'] = result['PTS'] / (2.0 * result['TSA']).replace(0, np.nan)\n",
    "    \n",
    "    # Calculate per-game stats with validation\n",
    "    if 'games' in result.columns:\n",
    "        games_safe = result['games'].replace(0, np.nan)\n",
    "        \n",
    "        if 'PTS' in result.columns:\n",
    "            result['PPG'] = result['PTS'] / games_safe\n",
    "        if 'AST' in result.columns:\n",
    "            result['APG'] = result['AST'] / games_safe\n",
    "        if 'TRB' in result.columns:\n",
    "            result['RPG'] = result['TRB'] / games_safe\n",
    "    \n",
    "    print(f\"Season totals completed: {result.shape}\")\n",
    "    return result\n",
    "\n",
    "# ============================================================================\n",
    "# ADVANCED METRICS - SIMPLIFIED\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def compute_pie(player_games: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute player share of game 'PIE numerator' using only observed stats.\n",
    "    No invented baselines; no imputations.\n",
    "    \"\"\"\n",
    "    d = player_games.copy()\n",
    "    d['pie_num'] = (\n",
    "        d['PTS'] + d['FGM'] + d['FTM']\n",
    "        - d['FGA'] - d['FTA']\n",
    "        + d['DREB'] + 0.5*d['OREB'] + d['AST'] + d['STL'] + 0.5*d['BLK']\n",
    "        - d['PF'] - d['TOV']\n",
    "    )\n",
    "\n",
    "    game_totals = d.groupby('game_id', as_index=False)['pie_num'].sum().rename(columns={'pie_num':'game_pie_total'})\n",
    "    d = d.merge(game_totals, on='game_id', how='left')\n",
    "    d['pie'] = d['pie_num'] / d['game_pie_total'].replace(0, np.nan)\n",
    "\n",
    "    season_pie = (\n",
    "        d.groupby(['player_id','name','season'], as_index=False)\n",
    "         .apply(lambda x: pd.Series({'season_PIE': (x['pie']*x['minutes']).sum() / x['minutes'].sum()\n",
    "                                     if x['minutes'].sum() > 0 else np.nan}))\n",
    "         .reset_index(drop=True)\n",
    "    )\n",
    "    return season_pie\n",
    "\n",
    "def compute_per(player_games: pd.DataFrame, team_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean PER calculation with proper 3PT handling - no silent misalignment\n",
    "    \"\"\"\n",
    "    # Calculate league stats including 3PT properly\n",
    "    league_stats = team_df.groupby('season', as_index=False).agg({\n",
    "        'fieldGoalsMade': 'sum',\n",
    "        'fieldGoalsAttempted': 'sum',\n",
    "        'freeThrowsMade': 'sum',\n",
    "        'freeThrowsAttempted': 'sum',\n",
    "        'assists': 'sum',\n",
    "        'reboundsOffensive': 'sum',\n",
    "        'reboundsTotal': 'sum',\n",
    "        'turnovers': 'sum',\n",
    "        'threePointersMade': 'sum'  # Include 3PT in aggregation to avoid misalignment\n",
    "    })\n",
    "    \n",
    "    # Calculate possessions and VOP\n",
    "    league_stats['team_poss'] = (\n",
    "        league_stats['fieldGoalsAttempted'] - league_stats['reboundsOffensive'] +\n",
    "        league_stats['turnovers'] + 0.44 * league_stats['freeThrowsAttempted']\n",
    "    )\n",
    "    # FIXED: Include free throws in league points calculation for accurate VOP\n",
    "    league_stats['lg_pts'] = 2 * league_stats['fieldGoalsMade'] + league_stats['threePointersMade'] + league_stats['freeThrowsMade']\n",
    "    league_stats['VOP'] = league_stats['lg_pts'] / league_stats['team_poss'].replace(0, np.nan)\n",
    "    \n",
    "    # Merge with player data\n",
    "    d = player_games.merge(league_stats[['season', 'VOP']], on='season', how='left')\n",
    "    \n",
    "    # Calculate raw PER components\n",
    "    d['raw_per'] = (\n",
    "        d['3PM'] + 0.667 * d['AST'] + d['FGM'] + 0.5 * d['FTM'] +\n",
    "        d['VOP'] * (d['TRB'] + d['STL'] + d['BLK']) -\n",
    "        d['VOP'] * (d['TOV'] + (d['FGA'] - d['FGM']) + 0.44 * (d['FTA'] - d['FTM']))\n",
    "    )\n",
    "    \n",
    "    # Season PER - weighted by minutes\n",
    "    season_per = (\n",
    "        d.groupby(['player_id', 'name', 'season'], as_index=False)\n",
    "         .apply(lambda x: pd.Series({\n",
    "             'season_PER': (x['raw_per'] * x['minutes']).sum() / x['minutes'].sum()\n",
    "             if x['minutes'].sum() > 0 else np.nan\n",
    "         }))\n",
    "         .reset_index(drop=True)\n",
    "    )\n",
    "    \n",
    "    return season_per\n",
    "\n",
    "def calculate_metrics(player_df: pd.DataFrame, team_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ENHANCED VERSION: Main calculation pipeline with comprehensive error handling\n",
    "    \"\"\"\n",
    "    print(\"=== CALCULATING NBA METRICS (ENHANCED VERSION) ===\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Validate inputs\n",
    "        if player_df.empty:\n",
    "            raise ValueError(\"Player DataFrame is empty\")\n",
    "        if team_df.empty:\n",
    "            raise ValueError(\"Team DataFrame is empty\")\n",
    "        \n",
    "        print(f\"Input validation passed:\")\n",
    "        print(f\"  Player records: {len(player_df):,}\")\n",
    "        print(f\"  Team records: {len(team_df):,}\")\n",
    "        \n",
    "        # Step 2: Normalize data with validation\n",
    "        print(\"\\nStep 1: Normalizing player data...\")\n",
    "        player_normalized = normalize_player_data(player_df)\n",
    "        print(f\"✓ Normalized player data: {player_normalized.shape}\")\n",
    "        \n",
    "        # Validate normalization\n",
    "        required_cols = ['player_id', 'name', 'season', 'minutes']\n",
    "        missing_required = [col for col in required_cols if col not in player_normalized.columns]\n",
    "        if missing_required:\n",
    "            raise ValueError(f\"Missing required columns after normalization: {missing_required}\")\n",
    "\n",
    "        # Step 3: Build season totals with the FIXED function\n",
    "        print(\"\\nStep 2: Building season totals...\")\n",
    "        season_totals = build_season_totals(player_normalized)\n",
    "        print(f\"✓ Season totals: {season_totals.shape}\")\n",
    "        \n",
    "        # Validate season totals\n",
    "        if season_totals.empty:\n",
    "            raise RuntimeError(\"Season totals calculation resulted in empty DataFrame\")\n",
    "\n",
    "        # Step 4: Calculate PIE metrics\n",
    "        print(\"\\nStep 3: Calculating PIE...\")\n",
    "        try:\n",
    "            season_pie = compute_pie(player_normalized)\n",
    "            print(f\"✓ PIE calculated: {season_pie.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: PIE calculation failed: {e}\")\n",
    "            # Create empty PIE DataFrame to continue pipeline\n",
    "            season_pie = pd.DataFrame({\n",
    "                'player_id': season_totals['player_id'],\n",
    "                'name': season_totals['name'], \n",
    "                'season': season_totals['season'],\n",
    "                'season_PIE': np.nan\n",
    "            })\n",
    "\n",
    "        # Step 5: Calculate PER\n",
    "        print(\"\\nStep 4: Calculating PER...\")\n",
    "        try:\n",
    "            per_metrics = compute_per(player_normalized, team_df)\n",
    "            print(f\"✓ PER metrics calculated: {per_metrics.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: PER calculation failed: {e}\")\n",
    "            # Create empty PER DataFrame to continue pipeline\n",
    "            per_metrics = pd.DataFrame({\n",
    "                'player_id': season_totals['player_id'],\n",
    "                'name': season_totals['name'],\n",
    "                'season': season_totals['season'], \n",
    "                'season_PER': np.nan\n",
    "            })\n",
    "\n",
    "        # Step 6: Merge everything with validation\n",
    "        print(\"\\nStep 5: Merging datasets...\")\n",
    "        \n",
    "        # Merge PIE data\n",
    "        final_data = season_totals.merge(\n",
    "            season_pie, \n",
    "            on=['player_id', 'name', 'season'], \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"  After PIE merge: {final_data.shape}\")\n",
    "        \n",
    "        # Merge PER data  \n",
    "        final_data = final_data.merge(\n",
    "            per_metrics, \n",
    "            on=['player_id', 'name', 'season'], \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"  After PER merge: {final_data.shape}\")\n",
    "\n",
    "        # Step 7: Add per-36 stats\n",
    "        print(\"\\nStep 6: Adding per-36 statistics...\")\n",
    "        per36_stats = ['PTS', 'AST', 'TRB', 'STL', 'BLK', 'TOV']\n",
    "        available_per36 = [stat for stat in per36_stats if stat in final_data.columns]\n",
    "        \n",
    "        if available_per36:\n",
    "            final_data = add_per36(final_data, stat_cols=available_per36, minutes_col='minutes')\n",
    "            print(f\"✓ Per-36 stats added for: {available_per36}\")\n",
    "        else:\n",
    "            print(\"Warning: No stats available for per-36 calculation\")\n",
    "\n",
    "        # Final validation\n",
    "        print(f\"\\n✓ Final dataset: {final_data.shape}\")\n",
    "        print(f\"✓ Columns: {len(final_data.columns)}\")\n",
    "        \n",
    "        if final_data.empty:\n",
    "            raise RuntimeError(\"Final dataset is empty after processing\")\n",
    "            \n",
    "        # Quality checks\n",
    "        total_minutes = final_data['minutes'].sum()\n",
    "        valid_players = final_data['minutes'].notna().sum()\n",
    "        print(f\"✓ Quality check: {valid_players:,} players with valid minutes totaling {total_minutes:,.0f}\")\n",
    "        \n",
    "        return final_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ ERROR in calculate_metrics: {str(e)}\")\n",
    "        print(f\"✗ Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Detailed debugging info\n",
    "        if 'player_normalized' in locals():\n",
    "            print(f\"\\nDebug info:\")\n",
    "            print(f\"  Player normalized shape: {player_normalized.shape}\")\n",
    "            print(f\"  Player normalized columns: {sorted(player_normalized.columns)}\")\n",
    "            \n",
    "            # Check for data quality issues\n",
    "            minutes_issues = player_normalized['minutes'].isna().sum()\n",
    "            print(f\"  Minutes NaN count: {minutes_issues}\")\n",
    "            \n",
    "            if minutes_issues > 0:\n",
    "                print(f\"  Sample records with NaN minutes:\")\n",
    "                nan_sample = player_normalized[player_normalized['minutes'].isna()].head(3)\n",
    "                print(nan_sample[['name', 'season', 'minutes', 'PTS']].to_string())\n",
    "        \n",
    "        raise\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# INTERVIEW QUESTION FUNCTIONS - SIMPLIFIED\n",
    "# ============================================================================\n",
    "\n",
    "def add_team_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create team column from city and name - handle NaN values properly\"\"\"\n",
    "    if 'team' not in df.columns:\n",
    "        city = df['playerteamCity'].astype('string').fillna('')\n",
    "        name = df['playerteamName'].astype('string').fillna('')\n",
    "        df['team'] = (city + ' ' + name).str.strip()\n",
    "    return df\n",
    "\n",
    "def top_k_by_group(df: pd.DataFrame, metric: str, k: int, group_col=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    IMPROVED VERSION: Handles both single string and list of group columns\n",
    "    \"\"\"\n",
    "    if isinstance(group_col, str):\n",
    "        return df.groupby(group_col, group_keys=False).apply(lambda x: x.nlargest(k, metric)).reset_index(drop=True)\n",
    "    elif isinstance(group_col, list):\n",
    "        return df.groupby(group_col, group_keys=False).apply(lambda x: x.nlargest(k, metric)).reset_index(drop=True)\n",
    "    else:\n",
    "        return df.nlargest(k, metric)\n",
    "\n",
    "# Question implementations\n",
    "\n",
    "def question_1_top_scorers(df: pd.DataFrame, k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Top K players by PPG - direct operation\"\"\"\n",
    "    return df.nlargest(k, 'PPG')[['name', 'season', 'PPG', 'PTS', 'games']]\n",
    "\n",
    "\n",
    "\n",
    "def question_2_double_double_threshold(df: pd.DataFrame, pts_threshold: float = 25, reb_threshold: float = 10) -> pd.DataFrame:\n",
    "    \"\"\"Players above thresholds in multiple categories\"\"\"\n",
    "    mask = (df['PPG'] >= pts_threshold) & (df['RPG'] >= reb_threshold)\n",
    "    return df[mask][['name', 'season', 'PPG', 'RPG', 'PTS', 'TRB']]\n",
    "\n",
    "\n",
    "def question_3_correlation(df: pd.DataFrame, col1: str = 'minutes', col2: str = 'PTS') -> float:\n",
    "    \"\"\"Direct correlation calculation without verbose output\"\"\"\n",
    "    correlation = df[col1].corr(df[col2])\n",
    "    print(f\"Correlation between {col1} and {col2}: {correlation:.3f}\")\n",
    "    \n",
    "    if correlation > 0.7:\n",
    "        print(\"This indicates a strong positive relationship\")\n",
    "    elif correlation > 0.3:\n",
    "        print(\"This indicates a moderate positive relationship\")\n",
    "        \n",
    "    return correlation\n",
    "\n",
    "def question_4_true_shooting_leaders(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 4: Calculate shooting efficiency - players with best True Shooting %\"\"\"\n",
    "    print(\"\\n=== Question 4: True Shooting % Leaders ===\")\n",
    "    \n",
    "    # Step 1: Calculate True Shooting % if not exists\n",
    "    if 'TS_pct' not in df.columns:\n",
    "        df['TSA'] = df['FGA'] + 0.44 * df['FTA']\n",
    "        df['TS_pct'] = df['PTS'] / (2.0 * df['TSA']).replace(0, np.nan)\n",
    "    \n",
    "    # Step 2: Filter qualified players (minimum attempts)\n",
    "    qualified = df[df['TSA'] >= 100].copy()  # At least 100 true shot attempts\n",
    "    \n",
    "    # Step 3: Get top 10\n",
    "    result = qualified.nlargest(10, 'TS_pct')[['name', 'season', 'TS_pct', 'PTS', 'FGA', 'FTA']]\n",
    "    print(f\"Top 10 True Shooting % (min 100 TSA):{result}\")\n",
    "    return result\n",
    "\n",
    "def question_5_complete_players(df: pd.DataFrame, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Most complete players by combined stats\"\"\"\n",
    "    df['complete_score'] = df['PTS'] + df['AST'] + df['TRB']\n",
    "    return df.nlargest(k, 'complete_score')[['name', 'season', 'complete_score', 'PTS', 'AST', 'TRB']]\n",
    "\n",
    "def question_6_team_balance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    UPDATED VERSION: Uses unified calculate_team_scoring_balance function\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 6: Team Scoring Balance ===\")\n",
    "    return calculate_team_scoring_balance(df, group_cols=['team', 'season'])\n",
    "\n",
    "def question_7_clean_fg_percentage(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean FG% calculation - keep truthy NaNs instead of fabricating values\"\"\"\n",
    "    df = df.copy()\n",
    "    df['FG_pct'] = df['FGM'] / df['FGA'].replace(0, np.nan)\n",
    "    \n",
    "    missing = int(df['FG_pct'].isna().sum())\n",
    "    print(f\"Missing FG% values: {missing} (left as NaN to preserve data integrity)\")\n",
    "    return df\n",
    "\n",
    "def question_8_minutes_tiers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Question 8 using unified helper and safe MPG calculation\n",
    "    \n",
    "    Fixes: \n",
    "    - Uses safe_mpg_calculation to avoid inf values\n",
    "    - Uses unified assign_minutes_tier function\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 8: Minutes Tiers Analysis ===\")\n",
    "    \n",
    "    # Step 1: Create safe minutes per game calculation\n",
    "    df = df.copy()\n",
    "    df['MPG'] = safe_mpg_calculation(df, 'minutes', 'games')\n",
    "    \n",
    "    # Step 2: Use unified tier assignment\n",
    "    df['minutes_tier'] = df['MPG'].apply(assign_minutes_tier)\n",
    "    \n",
    "    # Step 3: Calculate tier averages\n",
    "    tier_stats = (df[df['minutes_tier'] != 'Other']\n",
    "                  .groupby('minutes_tier')\n",
    "                  .agg({\n",
    "                      'PTS': ['mean', 'median'],\n",
    "                      'AST': ['mean', 'median'],\n",
    "                      'TRB': ['mean', 'median'],\n",
    "                      'MPG': ['mean', 'count']\n",
    "                  }).round(1))\n",
    "    \n",
    "    # Flatten column names\n",
    "    tier_stats.columns = ['_'.join(col).strip() for col in tier_stats.columns]\n",
    "    tier_stats = tier_stats.reset_index()\n",
    "    \n",
    "    print(\"Average stats by minutes tier:\")\n",
    "    for i, row in tier_stats.iterrows():\n",
    "        print(f\"\\n{row['minutes_tier']} (n={row['MPG_count']:.0f}):\")\n",
    "        print(f\"  Points: {row['PTS_mean']:.1f} avg, {row['PTS_median']:.1f} median\")\n",
    "        print(f\"  Assists: {row['AST_mean']:.1f} avg, {row['AST_median']:.1f} median\")\n",
    "        print(f\"  Rebounds: {row['TRB_mean']:.1f} avg, {row['TRB_median']:.1f} median\")\n",
    "    \n",
    "    return tier_stats\n",
    "\n",
    "def question_9_guards_vs_forwards_scoring(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Require a real 'position' column; do not simulate.\"\"\"\n",
    "    print(\"\\n=== Question 9: Guards vs Forwards Scoring ===\")\n",
    "    if \"position\" not in df.columns:\n",
    "        raise ValueError(\"This analysis requires a real 'position' column. \"\n",
    "                         \"Provide roster/position data or skip this question.\")\n",
    "\n",
    "    guards_mask = df[\"position\"].isin([\"PG\",\"SG\"])\n",
    "    fwds_mask = df[\"position\"].isin([\"SF\",\"PF\",\"C\"])\n",
    "    guards = df.loc[guards_mask, \"PTS\"]\n",
    "    forwards = df.loc[fwds_mask, \"PTS\"]\n",
    "\n",
    "    t_stat, p_value = stats.ttest_ind(guards, forwards, equal_var=False, nan_policy=\"omit\")\n",
    "    results = {\n",
    "        'guards_mean': guards.mean(), 'guards_std': guards.std(), 'guards_n': guards.shape[0],\n",
    "        'forwards_mean': forwards.mean(), 'forwards_std': forwards.std(), 'forwards_n': forwards.shape[0],\n",
    "        't_statistic': t_stat, 'p_value': p_value, 'significant': p_value < 0.05\n",
    "    }\n",
    "    print(f\"Guards (n={results['guards_n']}): {results['guards_mean']:.1f} ± {results['guards_std']:.1f}\")\n",
    "    print(f\"Forwards (n={results['forwards_n']}): {results['forwards_mean']:.1f} ± {results['forwards_std']:.1f}\")\n",
    "    print(f\"T-test: t = {results['t_statistic']:.3f}, p = {results['p_value']:.3f} \"\n",
    "          f\"=> Significant: {'Yes' if results['significant'] else 'No'}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def question_10_efficiency_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    IMPROVED VERSION: Better labeling of efficiency metric when PER not available\n",
    "    \n",
    "    Fixes:\n",
    "    - Clear labeling when using fallback efficiency metric\n",
    "    - Better documentation of what the proxy metric represents\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 10: Efficiency Outliers ===\")\n",
    "    \n",
    "    # Use PER if available, otherwise create clearly labeled efficiency metric\n",
    "    if 'season_PER' in df.columns and df['season_PER'].notna().any():\n",
    "        efficiency = df['season_PER']\n",
    "        metric_name = 'season_PER'\n",
    "        print(\"Using official PER metric for outlier detection\")\n",
    "    else:\n",
    "        # Create proxy efficiency with clear labeling\n",
    "        print(\"PER not available - using simple efficiency proxy\")\n",
    "        print(\"Simple efficiency = (PTS + AST + TRB) / (FGA + TOV)\")\n",
    "        efficiency = (df['PTS'] + df['AST'] + df['TRB']) / (df['FGA'] + df['TOV']).replace(0, np.nan)\n",
    "        df['simple_efficiency'] = efficiency\n",
    "        metric_name = 'simple_efficiency'\n",
    "    \n",
    "    # IQR outlier detection\n",
    "    Q1, Q3 = efficiency.quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Find outliers\n",
    "    outlier_mask = (efficiency < lower_bound) | (efficiency > upper_bound)\n",
    "    outliers = df[outlier_mask].copy()\n",
    "    outliers['outlier_type'] = np.where(efficiency[outlier_mask] < lower_bound, 'Low', 'High')\n",
    "    \n",
    "    result = outliers[['name', 'season', metric_name, 'outlier_type']].sort_values(metric_name, ascending=False)\n",
    "    \n",
    "    print(f\"Found {len(result)} efficiency outliers using {metric_name}\")\n",
    "    for _, row in result.head(10).iterrows():\n",
    "        print(f\"{row['name']}: {row[metric_name]:.2f} ({row['outlier_type']} outlier)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_11_most_improved(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 11: Who improved the most from last season to this season?\"\"\"\n",
    "    print(\"\\n=== Question 11: Most Improved Players ===\")\n",
    "    \n",
    "    # Step 1: Calculate year-over-year improvement\n",
    "    df['season_year'] = df['season'].str[:4].astype(int)\n",
    "    \n",
    "    # Step 2: Get players with multiple seasons\n",
    "    player_seasons = df.groupby('player_id')['season_year'].nunique()\n",
    "    multi_season_players = player_seasons[player_seasons > 1].index\n",
    "    \n",
    "    # Step 3: Calculate improvement for multi-season players\n",
    "    improvements = []\n",
    "    \n",
    "    for player_id in multi_season_players:\n",
    "        player_data = df[df['player_id'] == player_id].sort_values('season_year')\n",
    "        \n",
    "        if len(player_data) >= 2:\n",
    "            current = player_data.iloc[-1]  # Most recent season\n",
    "            previous = player_data.iloc[-2]  # Previous season\n",
    "            \n",
    "            # Calculate improvement in PPG\n",
    "            ppg_improvement = current['PPG'] - previous['PPG']\n",
    "            \n",
    "            improvements.append({\n",
    "                'player_id': player_id,\n",
    "                'name': current['name'],\n",
    "                'previous_season': previous['season'],\n",
    "                'current_season': current['season'],\n",
    "                'previous_ppg': previous['PPG'],\n",
    "                'current_ppg': current['PPG'],\n",
    "                'ppg_improvement': ppg_improvement\n",
    "            })\n",
    "    \n",
    "    # Step 4: Find most improved\n",
    "    if improvements:\n",
    "        result = pd.DataFrame(improvements).nlargest(10, 'ppg_improvement')\n",
    "        \n",
    "        print(\"Most Improved Players (PPG increase):\")\n",
    "        for i, row in result.iterrows():\n",
    "            print(f\"{row['name']}: {row['previous_ppg']:.1f} → {row['current_ppg']:.1f} PPG (+{row['ppg_improvement']:.1f})\")\n",
    "    else:\n",
    "        result = pd.DataFrame()\n",
    "        print(\"No multi-season players found for improvement analysis\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_12_pie_top_10(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Use computed season PIE; do not approximate with ad-hoc denominator.\"\"\"\n",
    "    print(\"\\n=== Question 12: PIE Top 10 ===\")\n",
    "    pie_col = None\n",
    "    if \"season_PIE\" in df.columns:\n",
    "        pie_col = \"season_PIE\"\n",
    "    elif \"season_pie\" in df.columns:\n",
    "        pie_col = \"season_pie\"\n",
    "    elif \"season_pie_pct\" in df.columns:\n",
    "        pie_col = \"season_pie_pct\"\n",
    "    else:\n",
    "        raise ValueError(\"PIE not found on season table. Ensure compute_pie() ran before this step.\")\n",
    "\n",
    "    result = df.nlargest(10, pie_col)[[\"name\",\"season\",pie_col,\"PTS\",\"AST\",\"TRB\"]]\n",
    "    for _, row in result.iterrows():\n",
    "        v = row[pie_col] * (100 if \"pct\" in pie_col else 1.0)\n",
    "        label = \"%\" if \"pct\" in pie_col else \"\"\n",
    "        print(f\"{row['name']}: {v:.3f}{label} PIE\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ADVANCED QUESTIONS (13-22)\n",
    "# ============================================================================\n",
    "def question_13_top_scorers_per_team(df: pd.DataFrame, min_mpg: float = 15.0, k: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Uses per-game minutes filter as specified (≥15 MPG, not ≥900 total minutes)\n",
    "    \n",
    "    Fixes:\n",
    "    - Changed from season minutes (≥900) to per-game minutes (≥15 MPG)  \n",
    "    - Groups by team AND season to avoid conflating multi-season data\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Question 13: Top {k} Scorers Per Team (≥{min_mpg} MPG) ===\")\n",
    "    \n",
    "    df = add_team_column(df.copy())\n",
    "    \n",
    "    # Calculate MPG safely\n",
    "    df['MPG'] = safe_mpg_calculation(df, 'minutes', 'games')\n",
    "    \n",
    "    # Add per-36 stats if not present\n",
    "    if 'PTS_per36' not in df.columns:\n",
    "        df = add_per36(df, stat_cols=['PTS'], minutes_col='minutes')\n",
    "    \n",
    "    # Filter by MPG (per-game criteria, not season total)\n",
    "    qualified = df[df['MPG'] >= min_mpg].copy()\n",
    "    print(f\"Qualified players: {len(qualified)} (≥{min_mpg} MPG)\")\n",
    "    \n",
    "    # Group by team AND season (avoid conflating different seasons)\n",
    "    result = top_k_by_group(qualified, 'PTS_per36', k, group_col=['team', 'season'])\n",
    "    \n",
    "    print(f\"Top {k} scorers per team-season by points per-36:\")\n",
    "    current_team_season = None\n",
    "    for _, row in result.iterrows():\n",
    "        team_season = f\"{row['team']} ({row['season']})\"\n",
    "        if team_season != current_team_season:\n",
    "            current_team_season = team_season\n",
    "            print(f\"\\n{team_season}:\")\n",
    "        print(f\"  {row['name']}: {row['PTS_per36']:.1f} pts/36 ({row['MPG']:.1f} MPG)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def question_14_composite_impact_score(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Composite impact = z(PTS/36) + 0.7*z(AST/36) + 0.7*z(TRB/36)\n",
    "    - Works on the season-level table using totals + minutes.\n",
    "    - No reliance on game_id; no re-computation of game-level metrics.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 14: Composite Impact Score ===\")\n",
    "    required = ['minutes', 'PTS', 'AST', 'TRB']\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Q14 requires {missing} on the season table.\")\n",
    "\n",
    "    # Ensure per-36 columns exist\n",
    "    need_per36 = [c for c in ['PTS_per36', 'AST_per36', 'TRB_per36'] if c not in df.columns]\n",
    "    if need_per36:\n",
    "        df = add_per36(df, stats=['PTS', 'AST', 'TRB'])\n",
    "\n",
    "    # Standardize per-36 columns\n",
    "    df = standardize_columns(df, ['PTS_per36', 'AST_per36', 'TRB_per36'])\n",
    "\n",
    "    # Compute composite impact\n",
    "    if not set(['z_PTS_per36', 'z_AST_per36', 'z_TRB_per36']).issubset(df.columns):\n",
    "        raise RuntimeError(\"Z-scored per-36 columns not found after standardization.\")\n",
    "\n",
    "    df['impact_score'] = (\n",
    "        df['z_PTS_per36'] +\n",
    "        0.7 * df['z_AST_per36'] +\n",
    "        0.7 * df['z_TRB_per36']\n",
    "    )\n",
    "\n",
    "    # Rank (drop NaNs to avoid implicit imputation)\n",
    "    result = (df[['name', 'season', 'impact_score', 'PTS_per36', 'AST_per36', 'TRB_per36']]\n",
    "              .dropna(subset=['impact_score'])\n",
    "              .nlargest(10, 'impact_score'))\n",
    "\n",
    "    print(\"Top 10 Composite Impact Scores:\")\n",
    "    for _, row in result.iterrows():\n",
    "        print(f\"{row['name']}: {row['impact_score']:.2f} \"\n",
    "              f\"({row['PTS_per36']:.1f}P, {row['AST_per36']:.1f}A, {row['TRB_per36']:.1f}R per-36)\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def question_15_expected_points_model(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 15: Linear model for expected points, find positive residuals\"\"\"\n",
    "    print(\"\\n=== Question 15: Expected Points Model ===\")\n",
    "    \n",
    "    # Step 1: Prepare data for modeling - drop missing rows instead of zero-fill\n",
    "    features = ['minutes', 'AST', 'TRB']\n",
    "    needed = features + ['PTS']\n",
    "    mask = df[needed].notna().all(axis=1)\n",
    "    X = df.loc[mask, features]\n",
    "    y = df.loc[mask, 'PTS']\n",
    "    \n",
    "    # Step 2: Fit linear model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Step 3: Calculate predictions and residuals\n",
    "    df = df.copy()\n",
    "    df.loc[mask, 'predicted_PTS'] = model.predict(X)\n",
    "    df['PTS_residual'] = df['PTS'] - df['predicted_PTS']\n",
    "    \n",
    "    # Step 4: Get top 10 positive residuals (outperformers)\n",
    "    result = df.loc[mask].nlargest(10, 'PTS_residual')[['name', 'season', 'PTS', 'predicted_PTS', 'PTS_residual']]\n",
    "    \n",
    "    print(\"Top 10 Point Over-Performers (positive residuals):\")\n",
    "    print(f\"Model R² = {model.score(X, y):.3f}\")\n",
    "    for i, row in result.iterrows():\n",
    "        print(f\"{row['name']}: {row['PTS']:.0f} actual vs {row['predicted_PTS']:.0f} predicted (+{row['PTS_residual']:.0f})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_16_team_scoring_balance(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    UPDATED VERSION: Uses unified calculate_team_scoring_balance function\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 16: Team Scoring Balance (Detailed) ===\")\n",
    "    \n",
    "    result = calculate_team_scoring_balance(df, group_cols=['team', 'season'])\n",
    "    \n",
    "    print(\"Team Scoring Distribution (CV = std/mean):\")\n",
    "    print(\"Lower CV = More Balanced, Higher CV = More Star-Heavy\")\n",
    "    for i, row in result.head(10).iterrows():\n",
    "        print(f\"{row['team']}: CV = {row['cv']:.3f} ({row['balance_type']}, avg {row['mean']:.1f} pts)\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_17_minutes_tier_analysis(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    UPDATED VERSION: Uses unified helper functions\n",
    "    \n",
    "    - Uses safe_mpg_calculation for MPG\n",
    "    - Uses assign_minutes_tier for tier assignment  \n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 17: Detailed Minutes Tier Analysis ===\")\n",
    "    \n",
    "    # Use unified helpers\n",
    "    df = df.copy()\n",
    "    df['MPG'] = safe_mpg_calculation(df, 'minutes', 'games')\n",
    "    df['minutes_tier'] = df['MPG'].apply(assign_minutes_tier)\n",
    "    \n",
    "    # Step 2: Calculate comprehensive tier statistics\n",
    "    tier_stats = (df[df['minutes_tier'] != 'Other']\n",
    "                  .groupby('minutes_tier')\n",
    "                  .agg({\n",
    "                      'PTS': ['mean', 'median', 'std'],\n",
    "                      'AST': ['mean', 'median', 'std'],\n",
    "                      'TRB': ['mean', 'median', 'std'],\n",
    "                      'player_id': 'count'\n",
    "                  }).round(2))\n",
    "    \n",
    "    # Flatten column names\n",
    "    tier_stats.columns = ['_'.join(col).strip() for col in tier_stats.columns]\n",
    "    tier_stats = tier_stats.reset_index()\n",
    "    \n",
    "    print(\"Comprehensive minutes tier analysis:\")\n",
    "    for i, row in tier_stats.iterrows():\n",
    "        print(f\"\\n{row['minutes_tier']} (n={row['player_id_count']}):\")\n",
    "        print(f\"  Points: μ={row['PTS_mean']:.1f}, med={row['PTS_median']:.1f}, σ={row['PTS_std']:.1f}\")\n",
    "        print(f\"  Assists: μ={row['AST_mean']:.1f}, med={row['AST_median']:.1f}, σ={row['AST_std']:.1f}\")\n",
    "        print(f\"  Rebounds: μ={row['TRB_mean']:.1f}, med={row['TRB_median']:.1f}, σ={row['TRB_std']:.1f}\")\n",
    "    \n",
    "    return tier_stats\n",
    "\n",
    "def question_18_three_above_median(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 18: Players above team median in points, assists, and rebounds\"\"\"\n",
    "    print(\"\\n=== Question 18: Three-Above-Median Players ===\")\n",
    "    \n",
    "    # Step 1: Add team info\n",
    "    df = add_team_column(df.copy())  # Make self-sufficient\n",
    "    \n",
    "    # Step 2: Calculate team medians\n",
    "    team_medians = (df.groupby(['team', 'season'])\n",
    "                   .agg({'PTS': 'median', 'AST': 'median', 'TRB': 'median'})\n",
    "                   .add_suffix('_team_median')\n",
    "                   .reset_index())\n",
    "    \n",
    "    # Step 3: Merge with player data\n",
    "    df_with_medians = df.merge(team_medians, on=['team', 'season'])\n",
    "    \n",
    "    # Step 4: Find players above median in all three categories\n",
    "    above_all_three = df_with_medians[\n",
    "        (df_with_medians['PTS'] > df_with_medians['PTS_team_median']) &\n",
    "        (df_with_medians['AST'] > df_with_medians['AST_team_median']) &\n",
    "        (df_with_medians['TRB'] > df_with_medians['TRB_team_median'])\n",
    "    ]\n",
    "    \n",
    "    result = above_all_three[['name', 'team', 'season', 'PTS', 'AST', 'TRB']].sort_values(['team', 'PTS'], ascending=[True, False])\n",
    "    \n",
    "    print(\"Players above team median in Points, Assists, AND Rebounds:\")\n",
    "    current_team = None\n",
    "    for i, row in result.iterrows():\n",
    "        if row['team'] != current_team:\n",
    "            current_team = row['team']\n",
    "            print(f\"\\n{current_team}:\")\n",
    "        print(f\"  {row['name']}: {row['PTS']:.0f}P, {row['AST']:.0f}A, {row['TRB']:.0f}R\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_19_top_rebounders_per_team(df: pd.DataFrame, k: int = 2) -> pd.DataFrame:\n",
    "    \"\"\"Top rebounders per team using reusable function\"\"\"\n",
    "    df = add_team_column(df.copy())  # Make self-sufficient\n",
    "    return top_k_by_group(df, 'TRB', k, 'team')\n",
    "\n",
    "def question_20_team_effect_on_scoring(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    FIXED VERSION: Addresses multicollinearity in Ridge regression\n",
    "    \n",
    "    Fixes:\n",
    "    - Uses fit_intercept=False to avoid perfect multicollinearity\n",
    "    - Standardizes non-dummy features for better interpretability\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Question 20: Team Effect on Scoring (Fixed Ridge) ===\")\n",
    "    \n",
    "    df = add_team_column(df.copy())\n",
    "    \n",
    "    # Prepare features - drop missing rows\n",
    "    base_features = ['minutes', 'AST', 'TRB', 'PTS']\n",
    "    mask = df[base_features].notna().all(axis=1)\n",
    "    d = df.loc[mask].copy()\n",
    "    \n",
    "    # Standardize continuous features for better Ridge interpretability\n",
    "    continuous_features = ['minutes', 'AST', 'TRB']\n",
    "    d[continuous_features] = StandardScaler().fit_transform(d[continuous_features])\n",
    "    \n",
    "    # Create team dummies\n",
    "    team_dummies = pd.get_dummies(d['team'], prefix='team')\n",
    "    X = pd.concat([d[continuous_features], team_dummies], axis=1)\n",
    "    y = d['PTS']\n",
    "    \n",
    "    # FIXED: Use fit_intercept=False to avoid multicollinearity with full dummy encoding\n",
    "    ridge = Ridge(alpha=1.0, fit_intercept=False)\n",
    "    ridge.fit(X, y)\n",
    "    \n",
    "    # Step 4: Extract team coefficients using pandas operations\n",
    "    team_coeffs = (\n",
    "        pd.Series(ridge.coef_, index=X.columns)\n",
    "        .filter(like='team_')\n",
    "        .rename_axis('feature')\n",
    "        .reset_index()\n",
    "        .assign(team=lambda x: x['feature'].str.replace('team_', '', regex=False))\n",
    "        .rename(columns={0: 'coefficient'})[['team', 'coefficient']]\n",
    "        .sort_values('coefficient', ascending=False)\n",
    "    )\n",
    "    \n",
    "    print(\"Team effects on scoring (Ridge regression, no intercept):\")\n",
    "    print(\"Positive = team increases scoring, Negative = team decreases scoring\")\n",
    "    print(\"Note: Coefficients relative to zero (no reference team)\")\n",
    "    for i, row in team_coeffs.iterrows():\n",
    "        print(f\"{row['team']}: {row['coefficient']:+.2f}\")\n",
    "    \n",
    "    return team_coeffs\n",
    "\n",
    "def question_21_bootstrap_confidence_intervals(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 21: Bootstrap 95% CI for mean points per team\"\"\"\n",
    "    print(\"\\n=== Question 21: Bootstrap 95% CI for Team Scoring ===\")\n",
    "    \n",
    "    # Step 1: Add team info\n",
    "    df = add_team_column(df.copy())  # Make self-sufficient\n",
    "    \n",
    "    # Step 2: Bootstrap function\n",
    "    def bootstrap_mean(data, n_bootstrap=1000):\n",
    "        np.random.seed(42)\n",
    "        bootstrap_means = []\n",
    "        for _ in range(n_bootstrap):\n",
    "            sample = np.random.choice(data, size=len(data), replace=True)\n",
    "            bootstrap_means.append(np.mean(sample))\n",
    "        return np.array(bootstrap_means)\n",
    "    \n",
    "    # Step 3: Calculate bootstrap CIs for each team\n",
    "    team_cis = []\n",
    "    for team in df['team'].unique():\n",
    "        team_data = df[df['team'] == team]['PTS'].values\n",
    "        if len(team_data) > 5:  # Need enough data\n",
    "            bootstrap_means = bootstrap_mean(team_data)\n",
    "            ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "            ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "            observed_mean = np.mean(team_data)\n",
    "            \n",
    "            team_cis.append({\n",
    "                'team': team,\n",
    "                'mean': observed_mean,\n",
    "                'ci_lower': ci_lower,\n",
    "                'ci_upper': ci_upper,\n",
    "                'ci_width': ci_upper - ci_lower,\n",
    "                'n_players': len(team_data)\n",
    "            })\n",
    "    \n",
    "    result = pd.DataFrame(team_cis).sort_values('mean', ascending=False)\n",
    "    \n",
    "    print(\"Bootstrap 95% Confidence Intervals for Team Mean Scoring:\")\n",
    "    for i, row in result.iterrows():\n",
    "        print(f\"{row['team']}: {row['mean']:.1f} [{row['ci_lower']:.1f}, {row['ci_upper']:.1f}] (n={row['n_players']})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def question_22_duplicate_detection(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Question 22: Detect and handle duplicate (player_id, name, season) rows\"\"\"\n",
    "    print(\"\\n=== Question 22: Duplicate Detection and Handling ===\")\n",
    "    \n",
    "    # Step 1: Check for duplicates including season to avoid collapsing multi-season players\n",
    "    subset = ['player_id', 'name', 'season']\n",
    "    duplicate_mask = df.duplicated(subset=subset, keep=False)\n",
    "    duplicates = df[duplicate_mask].copy()\n",
    "    \n",
    "    print(f\"Found {duplicate_mask.sum()} rows with duplicate (player_id, name, season) combinations\")\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        # Step 2: Show duplicate groups\n",
    "        duplicate_groups = duplicates.groupby(subset).size().reset_index(name='count')\n",
    "        print(f\"Number of duplicate groups: {len(duplicate_groups)}\")\n",
    "        \n",
    "        # Step 3: Keep the row with max minutes for each duplicate group\n",
    "        cleaned_df = df.loc[df.groupby(subset)['minutes'].idxmax()]\n",
    "        \n",
    "        print(f\"After deduplication: {len(df)} → {len(cleaned_df)} rows\")\n",
    "        print(\"Kept records with maximum minutes played for each player\")\n",
    "        \n",
    "        # Step 4: Show some examples\n",
    "        print(\"\\nExample duplicate resolutions:\")\n",
    "        for i, row in duplicate_groups.head(5).iterrows():\n",
    "            player_duplicates = duplicates[\n",
    "                (duplicates['player_id'] == row['player_id']) & \n",
    "                (duplicates['name'] == row['name']) &\n",
    "                (duplicates['season'] == row['season'])\n",
    "            ].sort_values('minutes', ascending=False)\n",
    "            \n",
    "            print(f\"{row['name']} ({row['player_id']}): {row['count']} duplicates\")\n",
    "            print(f\"  Kept: {player_duplicates.iloc[0]['minutes']:.0f} minutes\")\n",
    "            if len(player_duplicates) > 1:\n",
    "                print(f\"  Removed: {player_duplicates.iloc[1]['minutes']:.0f} minutes\")\n",
    "        \n",
    "        return cleaned_df\n",
    "    else:\n",
    "        print(\"No duplicates found!\")\n",
    "        return df\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION WITH ALL QUESTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def run_all_interview_questions(df: pd.DataFrame):\n",
    "    \"\"\"Run all 22 interview questions in sequence\"\"\"\n",
    "    print(\"🏀 RUNNING ALL INTERVIEW QUESTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Basic Questions (1-12)\n",
    "    results['q1'] = question_1_top_scorers(df)\n",
    "    results['q2'] = question_2_double_double_threshold(df)\n",
    "    results['q3'] = question_3_correlation(df)\n",
    "    results['q4'] = question_4_true_shooting_leaders(df)\n",
    "    results['q5'] = question_5_complete_players(df)\n",
    "    results['q6'] = question_6_team_balance(df)\n",
    "    df = question_7_clean_fg_percentage(df)  # Modifies df\n",
    "    results['q8'] = question_8_minutes_tiers(df)\n",
    "    # results['q9'] = question_9_guards_vs_forwards_scoring(df) # no position column\n",
    "    results['q10'] = question_10_efficiency_outliers(df)\n",
    "    results['q11'] = question_11_most_improved(df)\n",
    "    results['q12'] = question_12_pie_top_10(df)\n",
    "    \n",
    "    # Advanced Questions (13-22)\n",
    "    results['q13'] = question_13_top_scorers_per_team(df)\n",
    "    results['q14'] = question_14_composite_impact_score(df)\n",
    "    results['q15'] = question_15_expected_points_model(df)\n",
    "    results['q16'] = question_16_team_scoring_balance(df)\n",
    "    results['q17'] = question_17_minutes_tier_analysis(df)\n",
    "    results['q18'] = question_18_three_above_median(df)\n",
    "    results['q19'] = question_19_top_rebounders_per_team(df)\n",
    "    results['q20'] = question_20_team_effect_on_scoring(df)\n",
    "    results['q21'] = question_21_bootstrap_confidence_intervals(df)\n",
    "    df_cleaned = question_22_duplicate_detection(df)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ ALL INTERVIEW QUESTIONS COMPLETED!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return results, df_cleaned\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "def main_analysis():\n",
    "    \"\"\"\n",
    "    ENHANCED VERSION: Main execution with comprehensive debugging\n",
    "    \"\"\"\n",
    "    print(\"🏀 NBA ANALYSIS PIPELINE - DEBUGGING VERSION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    base = Path(\"notebooks/5080_gpu/interview_prep/data/heat_base_data\")\n",
    "    player_df_csv_path = Path(base / \"player_statistics_used_Regular Season_from_2009.csv\")\n",
    "    team_df_csv_path = Path(base / \"team_statistics_used_Regular Season_from_2009.csv\")\n",
    "    schema_path = Path(\"notebooks/5080_gpu/interview_prep/data/schema.yaml\")  # FIXED: Convert to Path object\n",
    "    \n",
    "    # Enhanced file validation with type checking\n",
    "    print(\"Validating file paths...\")\n",
    "    files_to_check = [\n",
    "        (player_df_csv_path, \"player data\"),\n",
    "        (team_df_csv_path, \"team data\"), \n",
    "        (schema_path, \"schema\")\n",
    "    ]\n",
    "    \n",
    "    # DEBUG: Verify all paths are Path objects\n",
    "    for i, (path, name) in enumerate(files_to_check):\n",
    "        if not isinstance(path, Path):\n",
    "            raise TypeError(f\"Path {i+1} ({name}) is not a Path object: {type(path)}\")\n",
    "    \n",
    "    for path, name in files_to_check:\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"{name} file not found: {path}\")\n",
    "        file_size = path.stat().st_size / (1024**2)  # MB\n",
    "        print(f\"✓ Found {name}: {path} ({file_size:.1f} MB)\")\n",
    "    \n",
    "    # Load data with enhanced error handling\n",
    "    print(f\"\\nLoading data...\")\n",
    "    try:\n",
    "        # Load schema\n",
    "        schema = load_schema(str(schema_path))\n",
    "        print(f\"✓ Schema loaded successfully\")\n",
    "        print(f\"  Numerical columns: {len(schema.numerical)}\")\n",
    "        print(f\"  Nominal columns: {len(schema.nominal)}\")\n",
    "        print(f\"  ID columns: {len(schema.id_cols)}\")\n",
    "        \n",
    "        # Load datasets\n",
    "        player_df = load_data(str(player_df_csv_path), schema)\n",
    "        team_df = load_data(str(team_df_csv_path), schema)\n",
    "        \n",
    "        print(f\"✓ Data loading completed:\")\n",
    "        print(f\"  Player records: {len(player_df):,}\")\n",
    "        print(f\"  Team records: {len(team_df):,}\")\n",
    "        \n",
    "        # Enhanced data quality assessment\n",
    "        print(f\"\\nData quality assessment:\")\n",
    "        \n",
    "        # Check key columns\n",
    "        key_player_cols = ['personId', 'gameId', 'numMinutes', 'points', 'season']\n",
    "        available_key_cols = [col for col in key_player_cols if col in player_df.columns]\n",
    "        missing_key_cols = [col for col in key_player_cols if col not in player_df.columns]\n",
    "        \n",
    "        print(f\"  Key columns available: {len(available_key_cols)}/{len(key_player_cols)}\")\n",
    "        if missing_key_cols:\n",
    "            print(f\"  Missing key columns: {missing_key_cols}\")\n",
    "        \n",
    "        # Check for null values in critical columns\n",
    "        for col in available_key_cols:\n",
    "            null_count = player_df[col].isnull().sum()\n",
    "            null_pct = (null_count / len(player_df)) * 100\n",
    "            if null_pct > 0:\n",
    "                print(f\"  {col}: {null_count:,} nulls ({null_pct:.1f}%)\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Data loading error: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        raise\n",
    "    \n",
    "    # Calculate metrics with the ENHANCED function\n",
    "    print(f\"\\nCalculating metrics...\")\n",
    "    try:\n",
    "        final_data = calculate_metrics(player_df, team_df)\n",
    "        print(\"✓ Metrics calculation completed successfully\")\n",
    "        \n",
    "        # Enhanced result summary\n",
    "        print(f\"\\nFinal dataset summary:\")\n",
    "        print(f\"  Total records: {len(final_data):,}\")\n",
    "        print(f\"  Unique players: {final_data['player_id'].nunique():,}\")\n",
    "        print(f\"  Seasons covered: {sorted(final_data['season'].unique())}\")\n",
    "        print(f\"  Total minutes: {final_data['minutes'].sum():,.0f}\")\n",
    "        print(f\"  Average minutes per player: {final_data['minutes'].mean():.1f}\")\n",
    "        \n",
    "        # Check for data completeness\n",
    "        key_metrics = ['PTS', 'AST', 'TRB', 'minutes']\n",
    "        for metric in key_metrics:\n",
    "            if metric in final_data.columns:\n",
    "                valid_count = final_data[metric].notna().sum()\n",
    "                valid_pct = (valid_count / len(final_data)) * 100\n",
    "                print(f\"  {metric} completeness: {valid_count:,}/{len(final_data):,} ({valid_pct:.1f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Metrics calculation error: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Enhanced debugging output\n",
    "        print(f\"\\nEnhanced debugging information:\")\n",
    "        print(f\"Player DF info:\")\n",
    "        print(f\"  Shape: {player_df.shape}\")\n",
    "        print(f\"  Memory usage: {player_df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "        print(f\"  Columns: {len(player_df.columns)}\")\n",
    "        \n",
    "        # Show sample of actual data\n",
    "        print(f\"\\nSample player data:\")\n",
    "        sample_cols = ['personId', 'gameId', 'numMinutes', 'points'] \n",
    "        available_sample_cols = [col for col in sample_cols if col in player_df.columns]\n",
    "        if available_sample_cols:\n",
    "            print(player_df[available_sample_cols].head(3).to_string())\n",
    "        \n",
    "        raise\n",
    "    \n",
    "    # Filter qualified players with enhanced reporting\n",
    "    print(f\"\\nFiltering qualified players...\")\n",
    "    min_minutes = 500\n",
    "    qualified = final_data[final_data['minutes'] >= min_minutes]\n",
    "    \n",
    "    filtered_out = len(final_data) - len(qualified)\n",
    "    filter_pct = (filtered_out / len(final_data)) * 100\n",
    "    \n",
    "    print(f\"✓ Filtering completed:\")\n",
    "    print(f\"  Minimum minutes threshold: {min_minutes}\")\n",
    "    print(f\"  Qualified players: {len(qualified):,}\")\n",
    "    print(f\"  Filtered out: {filtered_out:,} ({filter_pct:.1f}%)\")\n",
    "    print(f\"  Final dataset shape: {qualified.shape}\")\n",
    "    \n",
    "    return qualified\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = main_analysis()\n",
    "    run_all_interview_questions(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165b5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data types from the dataset=======firstName                   object\n",
      "lastName                    object\n",
      "personId                     int64\n",
      "gameId                       int64\n",
      "gameDate                    object\n",
      "playerteamCity              object\n",
      "playerteamName              object\n",
      "opponentteamCity            object\n",
      "opponentteamName            object\n",
      "gameType                    object\n",
      "gameLabel                  float64\n",
      "gameSubLabel               float64\n",
      "seriesGameNumber           float64\n",
      "win                          int64\n",
      "home                         int64\n",
      "numMinutes                 float64\n",
      "points                     float64\n",
      "assists                    float64\n",
      "blocks                     float64\n",
      "steals                     float64\n",
      "fieldGoalsAttempted        float64\n",
      "fieldGoalsMade             float64\n",
      "fieldGoalsPercentage       float64\n",
      "threePointersAttempted     float64\n",
      "threePointersMade          float64\n",
      "threePointersPercentage    float64\n",
      "freeThrowsAttempted        float64\n",
      "freeThrowsMade             float64\n",
      "freeThrowsPercentage       float64\n",
      "reboundsDefensive          float64\n",
      "reboundsOffensive          float64\n",
      "reboundsTotal              float64\n",
      "foulsPersonal              float64\n",
      "turnovers                  float64\n",
      "plusMinusPoints            float64\n",
      "season                      object\n",
      "player_name                 object\n",
      "minutes_total              float64\n",
      "dtype: object\n",
      "data types from the dataset=======gameId                       int64\n",
      "gameDate                    object\n",
      "teamCity                    object\n",
      "teamName                    object\n",
      "teamId                       int64\n",
      "opponentTeamCity            object\n",
      "opponentTeamName            object\n",
      "opponentTeamId               int64\n",
      "home                         int64\n",
      "win                          int64\n",
      "teamScore                    int64\n",
      "opponentScore                int64\n",
      "assists                    float64\n",
      "blocks                     float64\n",
      "steals                     float64\n",
      "fieldGoalsAttempted        float64\n",
      "fieldGoalsMade             float64\n",
      "fieldGoalsPercentage       float64\n",
      "threePointersAttempted     float64\n",
      "threePointersMade          float64\n",
      "threePointersPercentage    float64\n",
      "freeThrowsAttempted        float64\n",
      "freeThrowsMade             float64\n",
      "freeThrowsPercentage       float64\n",
      "reboundsDefensive          float64\n",
      "reboundsOffensive          float64\n",
      "reboundsTotal              float64\n",
      "foulsPersonal              float64\n",
      "turnovers                  float64\n",
      "plusMinusPoints            float64\n",
      "numMinutes                 float64\n",
      "q1Points                   float64\n",
      "q2Points                   float64\n",
      "q3Points                   float64\n",
      "q4Points                   float64\n",
      "benchPoints                float64\n",
      "biggestLead                float64\n",
      "biggestScoringRun          float64\n",
      "leadChanges                float64\n",
      "pointsFastBreak            float64\n",
      "pointsFromTurnovers        float64\n",
      "pointsInThePaint           float64\n",
      "pointsSecondChance         float64\n",
      "timesTied                  float64\n",
      "timeoutsRemaining          float64\n",
      "seasonWins                 float64\n",
      "seasonLosses               float64\n",
      "coachId                    float64\n",
      "season                      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ColumnSchema(BaseModel):\n",
    "    y_variable: str\n",
    "    ordinal: List[str]\n",
    "    nominal: List[str]\n",
    "    numerical: List[str]\n",
    "    id_cols: List[str]\n",
    "    \n",
    "    \n",
    "def load_schema(yaml_path, debug=False):\n",
    "    cfg = OmegaConf.load(yaml_path)\n",
    "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "    if debug:\n",
    "        print(f\"cfg_dict============={cfg_dict}\")\n",
    "    return ColumnSchema(**cfg_dict)\n",
    "\n",
    "\n",
    "def load_data(csv_path: str, schema: ColumnSchema,  sample_size: int = 100, sample: bool = False, debug: bool = False):\n",
    "    dtype_data = pd.read_csv(csv_path, nrows=sample_size)\n",
    "    if debug:\n",
    "        print(f\"data types from the dataset======={dtype_data.dtypes}\")\n",
    "    \n",
    "    dtype_map = {}\n",
    "    \n",
    "    for cols in schema.nominal + schema.id_cols + schema.ordinal:\n",
    "        dtype_map = \"string\"\n",
    "\n",
    "    if sample:\n",
    "        data = pd.read_csv(csv_path, nrows=sample_size)\n",
    "    else:\n",
    "        data = pd.read_csv(csv_path, dtype=dtype_map)\n",
    "\n",
    "    for col in schema.numerical:\n",
    "        if col in data.columns:\n",
    "            data[col] = pd.to_numeric(data[col])\n",
    "\n",
    "    return data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base = Path(\"notebooks/5080_gpu/interview_prep/data/heat_base_data\")\n",
    "    player_df_csv_path = Path(base / \"player_statistics_used_Regular Season_from_2009.csv\")\n",
    "    team_df_csv_path = Path(base / \"team_statistics_used_Regular Season_from_2009.csv\")\n",
    "    schema_path = Path(\"notebooks/5080_gpu/interview_prep/data/schema.yaml\")  # FIXED: Convert to Path object\n",
    "    \n",
    "    schema = load_schema(schema_path)\n",
    "    \n",
    "    player_data = load_data(player_df_csv_path, schema, debug=True)\n",
    "    team_data = load_data(team_df_csv_path, schema, debug=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa26054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
